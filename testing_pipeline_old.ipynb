{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNRTHIs-PTJu"
      },
      "source": [
        "# this notebook only predicts the CUI based on BERT model ie only if there are multiple candidates for a mention.\n",
        "# Steps to run this notebook.\n",
        "# 0. Switch to GPU first\n",
        "# 1. Mount Gdrive with model and meta files using the GUI on left plane.\n",
        "# 2. Upload a file \"data_for_BERT.csv\" that will be used by the BERT\n",
        "# 3. RUN ALL cells\n",
        "# 4. File called \"file_with_prediction.csv\" will be generated which can be used to verify\\analyse result"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80bIHWL_6giK"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1eL9d0f6PNp",
        "outputId": "a8d23748-c8e6-40ce-9da5-7808c6d2ad4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp \"/content/drive/My Drive/meta.bin\" meta.bin\n",
        "!cp \"/content/drive/My Drive/model.bin\" model.bin"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjlilUlg6dkU"
      },
      "source": [
        "import torch, joblib\n",
        "model = torch.load(\"model.bin\")\n",
        "meta = joblib.load(\"meta.bin\")\n",
        "enc_label = meta['enc_label']\n",
        "le_dict = dict(zip(enc_label.classes_, enc_label.transform(enc_label.classes_)))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY8IqR6d9ctD"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from tqdm import tqdm\n",
        "from sklearn import preprocessing\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "    \n",
        "class config:\n",
        "    TRAIN_PATH = \"./train\"\n",
        "    MAX_LEN = 64\n",
        "    TOKENIZER = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "    BATCH_SIZE = 32\n",
        "    EPOCHS = 10"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIxU_rK36fAs"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "test_df = pd.read_csv(\"data_for_BERT.csv\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm5aOZTaGHzZ"
      },
      "source": [
        "for i in test_df.index:\n",
        "    try:\n",
        "        test_df.at[i, 'prediction'] = eval(test_df['prediction'].loc[i])\n",
        "    except:\n",
        "        print(\"C\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB-CFzyP7SiB",
        "outputId": "03e49362-72b2-4d5e-afe2-791ad00abbbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_ids = []\n",
        "input_target_positions = []\n",
        "labels = []\n",
        "test_candidates = []\n",
        "enc_label = enc_label\n",
        "tokenizer = config.TOKENIZER\n",
        "mask_token = tokenizer.tokenize(\"[MASK]\")\n",
        "\n",
        "for index in tqdm(test_df.index):\n",
        "    row = test_df.loc[index]\n",
        "    sentence = row['original_sentence']\n",
        "    st = row['position_start']\n",
        "    end = row['position_end']\n",
        "    candidates = row['prediction']\n",
        "\n",
        "    tokenized_pre = tokenizer.tokenize(sentence[:st])\n",
        "    target_position = len(tokenized_pre)\n",
        "    if target_position > config.MAX_LEN//2:\n",
        "        tokenized_pre = tokenized_pre[-config.MAX_LEN//2:]\n",
        "        target_position = len(tokenized_pre)\n",
        "\n",
        "    tokenized_post = tokenizer.tokenize(sentence[end+1:])\n",
        "    tokenized = tokenized_pre + (mask_token) + tokenized_post\n",
        "    ids = tokenizer.convert_tokens_to_ids(tokenized)\n",
        "    ids = ids[(len(ids)-config.MAX_LEN)//2+1 : (len(ids)+config.MAX_LEN)//2-1]\n",
        "    \n",
        "    input_ids.append(ids)\n",
        "    input_target_positions.append(target_position)\n",
        "    labels.append(row['cui'])\n",
        "    test_candidates.append([le_dict.get(_, enc_label.transform(['CUI-less'])[0]) for _ in candidates])\n",
        "\n",
        "labels = [le_dict.get(_, enc_label.transform(['CUI-less'])[0]) for _ in labels] #enc_label.transform(labels)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 343/343 [00:06<00:00, 53.84it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW24w5ubLxOm",
        "outputId": "98e44224-eeb1-413e-b4dc-9119432fab93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "le_dict.get('C0019699', enc_label.transform(['CUI-less'])[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "749"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUeazMU-8WfJ"
      },
      "source": [
        "attention_masks = []\n",
        "for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKvOKcwSEcUn"
      },
      "source": [
        "max_len = max([len(_) for _ in test_candidates])\n",
        "for i in range(len(test_candidates)):\n",
        "    test_candidates[i] = test_candidates[i] + [enc_label.transform(['CUI-less'])[0]] * (max_len - len(test_candidates[i]))\n",
        "max_len = max([len(_) for _ in test_candidates])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FND8rFXV606k"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "input_ids = torch.tensor(input_ids)\n",
        "attention_masks = torch.tensor(attention_masks)\n",
        "labels = torch.tensor(labels)\n",
        "input_target_positions = torch.tensor(input_target_positions)\n",
        "test_candidates = torch.tensor(test_candidates)\n",
        "\n",
        "test_data = TensorDataset(input_ids, attention_masks, labels, input_target_positions, test_candidates)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "prediction_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=config.BATCH_SIZE)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIJLlkGO61bW"
      },
      "source": [
        "predictions , true_labels = [], []\n",
        "model.eval()\n",
        "for batch in prediction_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels, b_pos, b_candidates = batch\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    logits = np.argsort(logits, axis=1)\n",
        "    preds = []\n",
        "    for i in range(len(logits)):\n",
        "        for _ in logits[i]:\n",
        "            if _ in b_candidates[i]:\n",
        "                pred = _\n",
        "                break\n",
        "            else:\n",
        "                pred = logits[i][0]\n",
        "        preds.append(pred)\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    predictions.append(preds)\n",
        "    true_labels.append(label_ids)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWkAT8JE61jJ",
        "outputId": "3c106356-a677-4338-8425-1eaa996afeff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(flat_true_labels, flat_predictions))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.577259475218659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWTMNjb-Nn2_"
      },
      "source": [
        "test_df['BERT_prediction'] = enc_label.inverse_transform(flat_predictions)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJcpg4BSNwHo"
      },
      "source": [
        "test_df.to_csv(\"file_with_prediction.csv\")\n",
        "!cp file_with_prediction.csv \"/content/drive/My Drive/file_with_prediction.csv\""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6VnozBn_69o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}